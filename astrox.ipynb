{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:12:00.579381Z",
     "iopub.status.busy": "2021-04-29T06:12:00.579074Z",
     "iopub.status.idle": "2021-04-29T06:12:01.224236Z",
     "shell.execute_reply": "2021-04-29T06:12:01.223330Z",
     "shell.execute_reply.started": "2021-04-29T06:12:00.579351Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import PIL.Image\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.applications.densenet import preprocess_input, DenseNet121\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras import layers, Sequential, Model\n",
    "from tensorflow.keras.layers import concatenate, Dense\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, f1_score, classification_report, balanced_accuracy_score\n",
    "%matplotlib inline\n",
    "df = pd.read_csv(\"./df_astrox.csv\")\n",
    "\n",
    "# df['class']: Label\n",
    "# df['filename']: Filename for Chest radiographs (i.e. 'patient00001.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:12:02.893673Z",
     "iopub.status.busy": "2021-04-29T06:12:02.893349Z",
     "iopub.status.idle": "2021-04-29T06:12:02.899907Z",
     "shell.execute_reply": "2021-04-29T06:12:02.898977Z",
     "shell.execute_reply.started": "2021-04-29T06:12:02.893640Z"
    }
   },
   "outputs": [],
   "source": [
    "def resize(img, size, padColor=0):\n",
    "    interp = cv.INTER_AREA\n",
    "    h, w = img.shape[:2]\n",
    "    sh, sw = size\n",
    "    if h > w:\n",
    "        img2 = img[0:w, 0:w]\n",
    "    else:\n",
    "        img2 = img[0:h, 0:h]\n",
    "    scaled_img = cv.resize(img2, size, interpolation=interp)\n",
    "    return scaled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:12:35.778777Z",
     "iopub.status.busy": "2021-04-29T06:12:35.778463Z",
     "iopub.status.idle": "2021-04-29T06:12:45.027686Z",
     "shell.execute_reply": "2021-04-29T06:12:45.026664Z",
     "shell.execute_reply.started": "2021-04-29T06:12:35.778743Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5361/5361 [00:09<00:00, 581.28it/s]\n"
     ]
    }
   ],
   "source": [
    "for img_path in tqdm(glob.glob('./images/*.jpg')):\n",
    "    img = cv.imread(img_path)\n",
    "    img = resize(img, (224,224), 0)\n",
    "    file_name = './images/resize/' + img_path.split(\"/\")[-1]\n",
    "    cv.imwrite(file_name, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:12:45.040957Z",
     "iopub.status.busy": "2021-04-29T06:12:45.040727Z",
     "iopub.status.idle": "2021-04-29T06:12:53.895830Z",
     "shell.execute_reply": "2021-04-29T06:12:53.894821Z",
     "shell.execute_reply.started": "2021-04-29T06:12:45.040930Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5361/5361 [00:08<00:00, 607.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for img_path in tqdm(glob.glob('./images/resize/*.jpg')):\n",
    "    img = cv.imread(img_path)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    equ = cv.equalizeHist(img)\n",
    "    file_name = './images/he/' + img_path.split(\"/\")[-1]\n",
    "    cv.imwrite(file_name, equ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T04:18:32.196000Z",
     "iopub.status.busy": "2021-04-29T04:18:32.195674Z",
     "iopub.status.idle": "2021-04-29T04:18:32.199618Z",
     "shell.execute_reply": "2021-04-29T04:18:32.198893Z",
     "shell.execute_reply.started": "2021-04-29T04:18:32.195967Z"
    }
   },
   "source": [
    "# Train / valid / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:12:53.908811Z",
     "iopub.status.busy": "2021-04-29T06:12:53.908598Z",
     "iopub.status.idle": "2021-04-29T06:12:53.929019Z",
     "shell.execute_reply": "2021-04-29T06:12:53.928273Z",
     "shell.execute_reply.started": "2021-04-29T06:12:53.908785Z"
    }
   },
   "outputs": [],
   "source": [
    "df['file_path'] = './images/he/' + df['file_name'] \n",
    "\n",
    "df_trainvalid, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_valid = train_test_split(df_trainvalid, test_size=0.2, random_state=42)\n",
    "\n",
    "# TRAINING SET\n",
    "train_ce = df_train[df_train['class'] == \"ce\"].file_path.tolist()\n",
    "train_non_ce = df_train[df_train['class'] == \"non_ce\"].file_path.tolist()\n",
    "\n",
    "# VALIDATION SET\n",
    "val_files = df_valid.file_path.tolist()\n",
    "val_label = df_valid['class'].apply(lambda x: 1 if x == \"ce\" else 0).to_numpy()\n",
    "\n",
    "# TEST SET\n",
    "test_files = df_test.file_path_he.tolist()\n",
    "test_label = df_test['class'].apply(lambda x: 1 if x == \"ce\" else 0).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:12:55.789348Z",
     "iopub.status.busy": "2021-04-29T06:12:55.789068Z",
     "iopub.status.idle": "2021-04-29T06:12:55.794886Z",
     "shell.execute_reply": "2021-04-29T06:12:55.794006Z",
     "shell.execute_reply.started": "2021-04-29T06:12:55.789319Z"
    }
   },
   "outputs": [],
   "source": [
    "data_aug_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=10,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  zoom_range=[0.95, 1.05],\n",
    "                                  fill_mode='constant', cval=0)\n",
    "valset_gen = ImageDataGenerator(rescale=1./255)\n",
    "testset_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T04:49:19.506140Z",
     "iopub.status.busy": "2021-04-29T04:49:19.505824Z",
     "iopub.status.idle": "2021-04-29T04:49:19.509719Z",
     "shell.execute_reply": "2021-04-29T04:49:19.508964Z",
     "shell.execute_reply.started": "2021-04-29T04:49:19.506107Z"
    }
   },
   "source": [
    "### Train: Augmentation CE x 6, Train Non-CE x 3 \n",
    "### Valid, Test: no augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:12:59.061181Z",
     "iopub.status.busy": "2021-04-29T06:12:59.060946Z",
     "iopub.status.idle": "2021-04-29T06:13:45.506583Z",
     "shell.execute_reply": "2021-04-29T06:13:45.505685Z",
     "shell.execute_reply.started": "2021-04-29T06:12:59.061153Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ce_imgs = []\n",
    "for img_path in train_ce:\n",
    "    img = load_img(img_path)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    i = 0\n",
    "    for batch in data_aug_gen.flow(x, batch_size=1, seed=42):\n",
    "        train_ce_imgs.append(batch)\n",
    "        i += 1\n",
    "        if i == 6:\n",
    "            break\n",
    "train_ce_imgs = np.vstack(train_ce_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:13:45.566448Z",
     "iopub.status.busy": "2021-04-29T06:13:45.566220Z",
     "iopub.status.idle": "2021-04-29T06:14:42.454568Z",
     "shell.execute_reply": "2021-04-29T06:14:42.453706Z",
     "shell.execute_reply.started": "2021-04-29T06:13:45.566422Z"
    }
   },
   "outputs": [],
   "source": [
    "train_non_ce_imgs = []\n",
    "for img_path in train_non_ce:\n",
    "    img = load_img(img_path)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    i = 0\n",
    "    for batch in data_aug_gen.flow(x, batch_size=1, seed=42):\n",
    "        train_non_ce_imgs.append(batch)\n",
    "        i += 1\n",
    "        if i == 3:\n",
    "            break\n",
    "train_non_ce_imgs = np.vstack(train_non_ce_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:14:42.456568Z",
     "iopub.status.busy": "2021-04-29T06:14:42.456316Z",
     "iopub.status.idle": "2021-04-29T06:14:43.631481Z",
     "shell.execute_reply": "2021-04-29T06:14:43.630507Z",
     "shell.execute_reply.started": "2021-04-29T06:14:42.456538Z"
    }
   },
   "outputs": [],
   "source": [
    "val_imgs = []\n",
    "for img_path in val_files:\n",
    "    img = load_img(img_path)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    for batch in valset_gen.flow(x, batch_size=1, shuffle = False, seed=42):\n",
    "        val_imgs.append(batch)\n",
    "        break\n",
    "val_imgs = np.vstack(val_imgs)\n",
    "\n",
    "# 이건 순서대로 val_imgs 만 불러온 것 (no augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:14:43.632839Z",
     "iopub.status.busy": "2021-04-29T06:14:43.632608Z",
     "iopub.status.idle": "2021-04-29T06:14:45.109221Z",
     "shell.execute_reply": "2021-04-29T06:14:45.108389Z",
     "shell.execute_reply.started": "2021-04-29T06:14:43.632811Z"
    }
   },
   "outputs": [],
   "source": [
    "test_imgs = []\n",
    "for img_path in test_files:\n",
    "    img = load_img(img_path)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    for batch in testset_gen.flow(x, batch_size=1, shuffle = False, seed=42):\n",
    "        test_imgs.append(batch)\n",
    "        break\n",
    "test_imgs = np.vstack(test_imgs)\n",
    "# 이건 순서대로 test_imgs 만 불러온 것 (no augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:14:45.110643Z",
     "iopub.status.busy": "2021-04-29T06:14:45.110409Z",
     "iopub.status.idle": "2021-04-29T06:14:45.115001Z",
     "shell.execute_reply": "2021-04-29T06:14:45.114293Z",
     "shell.execute_reply.started": "2021-04-29T06:14:45.110613Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ce = [train_ce_imgs, np.repeat(1, train_ce_imgs.shape[0])]\n",
    "train_non_ce = [train_non_ce_imgs, np.repeat(0, train_non_ce_imgs.shape[0])]\n",
    "# label을 붙임 (1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:14:45.116206Z",
     "iopub.status.busy": "2021-04-29T06:14:45.115991Z",
     "iopub.status.idle": "2021-04-29T06:14:48.224674Z",
     "shell.execute_reply": "2021-04-29T06:14:48.223907Z",
     "shell.execute_reply.started": "2021-04-29T06:14:45.116180Z"
    }
   },
   "outputs": [],
   "source": [
    "train_img = np.concatenate((train_ce[0], train_non_ce[0]), axis=0)\n",
    "train_label = np.concatenate((train_ce[1], train_non_ce[1]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:14:48.239526Z",
     "iopub.status.busy": "2021-04-29T06:14:48.239313Z",
     "iopub.status.idle": "2021-04-29T06:26:00.585157Z",
     "shell.execute_reply": "2021-04-29T06:26:00.583701Z",
     "shell.execute_reply.started": "2021-04-29T06:14:48.239502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 364 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 364 all-reduces with algorithm = nccl, num_packs = 1\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4984\n",
      "Epoch 00001: val_loss improved from inf to 0.64433, saving model to ./model_astrox/model_ex-001_acc-0.644325.h5\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.6937 - accuracy: 0.4984 - val_loss: 0.6443 - val_accuracy: 0.7086\n",
      "Epoch 2/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.5701\n",
      "Epoch 00002: val_loss improved from 0.64433 to 0.62088, saving model to ./model_astrox/model_ex-002_acc-0.620879.h5\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 0.6707 - accuracy: 0.5701 - val_loss: 0.6209 - val_accuracy: 0.7147\n",
      "Epoch 3/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.6553 - accuracy: 0.6027\n",
      "Epoch 00003: val_loss improved from 0.62088 to 0.60814, saving model to ./model_astrox/model_ex-003_acc-0.608136.h5\n",
      "314/314 [==============================] - 36s 113ms/step - loss: 0.6553 - accuracy: 0.6027 - val_loss: 0.6081 - val_accuracy: 0.7377\n",
      "Epoch 4/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.6385 - accuracy: 0.6807\n",
      "Epoch 00004: val_loss improved from 0.60814 to 0.59345, saving model to ./model_astrox/model_ex-004_acc-0.593454.h5\n",
      "314/314 [==============================] - 36s 113ms/step - loss: 0.6385 - accuracy: 0.6807 - val_loss: 0.5935 - val_accuracy: 0.7730\n",
      "Epoch 5/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.6163 - accuracy: 0.7319\n",
      "Epoch 00005: val_loss improved from 0.59345 to 0.57576, saving model to ./model_astrox/model_ex-005_acc-0.575755.h5\n",
      "314/314 [==============================] - 35s 113ms/step - loss: 0.6163 - accuracy: 0.7319 - val_loss: 0.5758 - val_accuracy: 0.7745\n",
      "Epoch 6/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.7670\n",
      "Epoch 00006: val_loss improved from 0.57576 to 0.55549, saving model to ./model_astrox/model_ex-006_acc-0.555494.h5\n",
      "314/314 [==============================] - 36s 113ms/step - loss: 0.5847 - accuracy: 0.7670 - val_loss: 0.5555 - val_accuracy: 0.7822\n",
      "Epoch 7/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.5135 - accuracy: 0.8008\n",
      "Epoch 00007: val_loss improved from 0.55549 to 0.52492, saving model to ./model_astrox/model_ex-007_acc-0.524920.h5\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 0.5135 - accuracy: 0.8008 - val_loss: 0.5249 - val_accuracy: 0.7592\n",
      "Epoch 8/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.4622 - accuracy: 0.8004\n",
      "Epoch 00008: val_loss improved from 0.52492 to 0.50446, saving model to ./model_astrox/model_ex-008_acc-0.504464.h5\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 0.4622 - accuracy: 0.8004 - val_loss: 0.5045 - val_accuracy: 0.7715\n",
      "Epoch 9/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.4301 - accuracy: 0.8121\n",
      "Epoch 00009: val_loss improved from 0.50446 to 0.49079, saving model to ./model_astrox/model_ex-009_acc-0.490786.h5\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 0.4301 - accuracy: 0.8121 - val_loss: 0.4908 - val_accuracy: 0.7791\n",
      "Epoch 10/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.4120 - accuracy: 0.8147\n",
      "Epoch 00010: val_loss improved from 0.49079 to 0.47820, saving model to ./model_astrox/model_ex-010_acc-0.478204.h5\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 0.4120 - accuracy: 0.8147 - val_loss: 0.4782 - val_accuracy: 0.7883\n",
      "Epoch 11/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.3979 - accuracy: 0.8263\n",
      "Epoch 00011: val_loss improved from 0.47820 to 0.46750, saving model to ./model_astrox/model_ex-011_acc-0.467503.h5\n",
      "314/314 [==============================] - 36s 113ms/step - loss: 0.3979 - accuracy: 0.8263 - val_loss: 0.4675 - val_accuracy: 0.7929\n",
      "Epoch 12/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.3864 - accuracy: 0.8349\n",
      "Epoch 00012: val_loss improved from 0.46750 to 0.45670, saving model to ./model_astrox/model_ex-012_acc-0.456697.h5\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 0.3864 - accuracy: 0.8349 - val_loss: 0.4567 - val_accuracy: 0.8037\n",
      "Epoch 13/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.3729 - accuracy: 0.8408\n",
      "Epoch 00013: val_loss improved from 0.45670 to 0.44772, saving model to ./model_astrox/model_ex-013_acc-0.447717.h5\n",
      "314/314 [==============================] - 36s 114ms/step - loss: 0.3729 - accuracy: 0.8408 - val_loss: 0.4477 - val_accuracy: 0.7991\n",
      "Epoch 14/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.8474\n",
      "Epoch 00014: val_loss improved from 0.44772 to 0.44194, saving model to ./model_astrox/model_ex-014_acc-0.441940.h5\n",
      "314/314 [==============================] - 35s 113ms/step - loss: 0.3628 - accuracy: 0.8474 - val_loss: 0.4419 - val_accuracy: 0.7991\n",
      "Epoch 15/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8458\n",
      "Epoch 00015: val_loss improved from 0.44194 to 0.43647, saving model to ./model_astrox/model_ex-015_acc-0.436470.h5\n",
      "314/314 [==============================] - 35s 113ms/step - loss: 0.3631 - accuracy: 0.8458 - val_loss: 0.4365 - val_accuracy: 0.8113\n",
      "Epoch 16/1000\n",
      "196/314 [=================>............] - ETA: 12s - loss: 0.3581 - accuracy: 0.8466"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-75eb9ede6a81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m                            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                            \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                            callbacks=[checkpoint, early_stopping])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "densenet = DenseNet121(\n",
    "    weights='./brucechou1983_CheXNet_Keras_0.3.0_weights.h5',\n",
    "    include_top=True,\n",
    "    input_shape=(224, 224, 3),\n",
    "    classes=14\n",
    ")\n",
    "out = layers.Dense(1, activation='sigmoid')(densenet.layers[-2].output)\n",
    "model = tf.keras.Model(inputs=densenet.input, outputs=out)\n",
    "\n",
    "\n",
    "trained_model_dir = './model_astrox/'\n",
    "model_name = 'model_ex-{epoch:03d}_acc-{val_loss:03f}.h5'\n",
    "model_path = os.path.join(trained_model_dir, model_name)\n",
    "\n",
    "\n",
    "# Callback\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=model_path,\n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=1,\n",
    "                                                save_weights_only=False,\n",
    "                                                save_best_only=True,\n",
    "                                                mode='auto',\n",
    "                                                save_freq='epoch')\n",
    "early_stopping = EarlyStopping(patience=50)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history_model = model.fit(train_img, train_label,\n",
    "                          validation_data=(val_imgs, val_label),\n",
    "                          epochs=epochs,\n",
    "                          shuffle=True,\n",
    "                          batch_size=batch_size,\n",
    "                          steps_per_epoch=len(train_img)//batch_size,\n",
    "                          callbacks=[checkpoint, early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:26:03.445996Z",
     "iopub.status.busy": "2021-04-29T06:26:03.445665Z",
     "iopub.status.idle": "2021-04-29T06:26:08.695426Z",
     "shell.execute_reply": "2021-04-29T06:26:08.694610Z",
     "shell.execute_reply.started": "2021-04-29T06:26:03.445956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "trained_model_dir = './model_astrox/'\n",
    "\n",
    "model = tf.keras.models.load_model(os.path.join(\n",
    "    trained_model_dir, os.listdir(trained_model_dir)[-1]))\n",
    "\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:26:10.284501Z",
     "iopub.status.busy": "2021-04-29T06:26:10.284229Z",
     "iopub.status.idle": "2021-04-29T06:26:13.056078Z",
     "shell.execute_reply": "2021-04-29T06:26:13.055202Z",
     "shell.execute_reply.started": "2021-04-29T06:26:10.284471Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true = test_label\n",
    "predictions = model.predict(test_imgs)\n",
    "y_pred = (predictions > 0.5).astype(np.int)\n",
    "y_proba = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:26:14.312018Z",
     "iopub.status.busy": "2021-04-29T06:26:14.311773Z",
     "iopub.status.idle": "2021-04-29T06:26:14.334976Z",
     "shell.execute_reply": "2021-04-29T06:26:14.334226Z",
     "shell.execute_reply.started": "2021-04-29T06:26:14.311989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[119 133]\n",
      " [ 47 517]]\n",
      "Acc 0.7794117647058824\n",
      "Sensitivity 0.4722222222222222\n",
      "Specificity 0.9166666666666666\n",
      "AUROC 0.7720224023415513\n",
      "Recall 0.4722222222222222\n",
      "F1 0.569377990430622\n",
      "Weighted accuracy 0.6944444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.85       564\n",
      "           1       0.72      0.47      0.57       252\n",
      "\n",
      "    accuracy                           0.78       816\n",
      "   macro avg       0.76      0.69      0.71       816\n",
      "weighted avg       0.77      0.78      0.76       816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
    "TP = conf_mat[0][0]\n",
    "TN = conf_mat[1][1]\n",
    "FN = conf_mat[0][1]\n",
    "FP = conf_mat[1][0]\n",
    "print(conf_mat)\n",
    "print(\"Acc\", (TP+TN)/(TP+TN+FP+FN))\n",
    "print(\"Sensitivity\", TP/(TP+FN))\n",
    "print(\"Specificity\", TN/(TN+FP))\n",
    "print(\"AUROC\", roc_auc_score(y_true, y_proba))\n",
    "print(\"Recall\", recall_score(y_true, y_pred))\n",
    "print(\"F1\",  f1_score(y_true, y_pred))\n",
    "print(\"Weighted accuracy\", balanced_accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:26:20.637744Z",
     "iopub.status.busy": "2021-04-29T06:26:20.637413Z",
     "iopub.status.idle": "2021-04-29T06:26:20.817381Z",
     "shell.execute_reply": "2021-04-29T06:26:20.816675Z",
     "shell.execute_reply.started": "2021-04-29T06:26:20.637710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7720224023415513"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
    "\n",
    "\n",
    "def plot_roc(fpr, tpr):\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label=\"random guess\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_roc(fpr, tpr)\n",
    "roc_auc_score(y_true, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:26:52.842343Z",
     "iopub.status.busy": "2021-04-29T06:26:52.842022Z",
     "iopub.status.idle": "2021-04-29T06:26:52.854074Z",
     "shell.execute_reply": "2021-04-29T06:26:52.853292Z",
     "shell.execute_reply.started": "2021-04-29T06:26:52.842311Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_gradcam(model, IMAGE_PATH, LAYER_NAME):\n",
    "    image_array = IMAGE_PATH\n",
    "    img = image_array.astype(np.float32)\n",
    "\n",
    "    # Create a graph that outputs target convolution and output\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(LAYER_NAME).output, model.output])\n",
    "\n",
    "    # Get the score for target class\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.array([img]))\n",
    "        loss = predictions\n",
    "\n",
    "    # Extract filters and gradients\n",
    "    output = conv_outputs[0]\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "\n",
    "    # Average gradients spatially\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "\n",
    "    # Build a ponderated map of filters according to gradients importance\n",
    "    cam = np.ones(output.shape[0:2], dtype=np.float32)\n",
    "\n",
    "    for index, w in enumerate(weights):\n",
    "        cam += w * output[:, :, index]\n",
    "\n",
    "    # Heatmap visualization\n",
    "    cam = cv2.resize(cam.numpy(), (224, 224))\n",
    "    cam = np.maximum(cam, 0)\n",
    "\n",
    "    heatmap = ((cam - cam.min()) / (cam.max() - cam.min()))\n",
    "\n",
    "    cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "    alphanum = 0.6\n",
    "    output_image = cv2.addWeighted(cv2.cvtColor(\n",
    "        (image_array*255).astype('uint8'), cv2.COLOR_BGR2RGB), alphanum, cam, 1-alphanum, 0)\n",
    "    output_image = cv2.cvtColor(\n",
    "        output_image.astype('uint8'), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:27:41.789304Z",
     "iopub.status.busy": "2021-04-29T06:27:41.788986Z",
     "iopub.status.idle": "2021-04-29T06:27:41.794498Z",
     "shell.execute_reply": "2021-04-29T06:27:41.793757Z",
     "shell.execute_reply.started": "2021-04-29T06:27:41.789272Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_class(model, IMAGE_PATH):\n",
    "    img = IMAGE_PATH\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    predictions = model.predict(img)\n",
    "    y_pred = (predictions > 0.5).astype(np.int)\n",
    "    return predictions, y_pred\n",
    "    print(predictions, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:34:42.671711Z",
     "iopub.status.busy": "2021-04-29T06:34:42.671406Z",
     "iopub.status.idle": "2021-04-29T06:34:42.674984Z",
     "shell.execute_reply": "2021-04-29T06:34:42.674325Z",
     "shell.execute_reply.started": "2021-04-29T06:34:42.671679Z"
    }
   },
   "source": [
    "### Save grad-cams for test dataset\n",
    "- file_name: id _ label _ sigmoid output _ predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:28:08.468060Z",
     "iopub.status.busy": "2021-04-29T06:28:08.467751Z",
     "iopub.status.idle": "2021-04-29T06:29:05.063443Z",
     "shell.execute_reply": "2021-04-29T06:29:05.062242Z",
     "shell.execute_reply.started": "2021-04-29T06:28:08.468029Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2d353143c33a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gradcam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     output_image = cv2.cvtColor(\n\u001b[1;32m      5\u001b[0m         output_image.astype('uint8'), cv2.COLOR_BGR2RGB)\n",
      "\u001b[0;32m<ipython-input-20-8e3017cf99ff>\u001b[0m in \u001b[0;36mget_gradcam\u001b[0;34m(model, IMAGE_PATH, LAYER_NAME)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mcam\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6929\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6930\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6931\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6932\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m   1194\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10315\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"begin_mask\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10316\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ellipsis_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10317\u001b[0;31m         \"new_axis_mask\", new_axis_mask, \"shrink_axis_mask\", shrink_axis_mask)\n\u001b[0m\u001b[1;32m  10318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10319\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(test_imgs)):\n",
    "    predictions = get_class(model, test_imgs[i])\n",
    "    output_image = get_gradcam(model, test_imgs[i], 'relu')\n",
    "    output_image = cv2.cvtColor(\n",
    "        output_image.astype('uint8'), cv2.COLOR_BGR2RGB)\n",
    "    file_name = './gradcam_astrox/' + str(i) + '_' + str(test_label[i]) + '_' + str(\n",
    "        predictions[0]) + '_' + str(predictions[1]) + '.jpg'\n",
    "    cv2.imwrite(file_name, output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
