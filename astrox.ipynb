{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import PIL.Image\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.applications.densenet import preprocess_input, DenseNet121\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras import layers, Sequential, Model\n",
    "from tensorflow.keras.layers import concatenate, Dense\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, f1_score, classification_report, balanced_accuracy_score\n",
    "%matplotlib inline\n",
    "df = pd.read_csv(\"./df_astrox.csv\")\n",
    "\n",
    "# df['class']: Label\n",
    "# df['filename']: Filename for Chest radiographs (i.e. 'patient00001.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img, size, padColor=0):\n",
    "    interp = cv.INTER_AREA\n",
    "    h, w = img.shape[:2]\n",
    "    sh, sw = size\n",
    "    if h > w:\n",
    "        img2 = img[0:w, 0:w]\n",
    "    else:\n",
    "        img2 = img[0:h, 0:h]\n",
    "    scaled_img = cv.resize(img2, size, interpolation=interp)\n",
    "    return scaled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in tqdm(glob.glob('./images/*.jpg')):\n",
    "    img = cv.imread(img_path)\n",
    "    img = resize(img, (224,224), 0)\n",
    "    file_name = './images/resize/' + img_path.split(\"/\")[-1]\n",
    "    cv.imwrite(file_name, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in tqdm(glob.glob('./images/resize/*.jpg')):\n",
    "    img = cv.imread(img_path)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    equ = cv.equalizeHist(img)\n",
    "    file_name = './images/he/' + img_path.split(\"/\")[-1]\n",
    "    cv.imwrite(file_name, equ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T04:18:32.196000Z",
     "iopub.status.busy": "2021-04-29T04:18:32.195674Z",
     "iopub.status.idle": "2021-04-29T04:18:32.199618Z",
     "shell.execute_reply": "2021-04-29T04:18:32.198893Z",
     "shell.execute_reply.started": "2021-04-29T04:18:32.195967Z"
    }
   },
   "source": [
    "# Train / valid / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['file_path'] = './images/he/' + df['file_name'] \n",
    "\n",
    "df_trainvalid, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_valid = train_test_split(df_trainvalid, test_size=0.2, random_state=42)\n",
    "\n",
    "# TRAINING SET\n",
    "train_ce = df_train[df_train['class'] == \"ce\"].file_path.tolist()\n",
    "train_non_ce = df_train[df_train['class'] == \"non_ce\"].file_path.tolist()\n",
    "\n",
    "# VALIDATION SET\n",
    "val_files = df_valid.file_path.tolist()\n",
    "val_label = df_valid['class'].apply(lambda x: 1 if x == \"ce\" else 0).to_numpy()\n",
    "\n",
    "# TEST SET\n",
    "test_files = df_test.file_path_he.tolist()\n",
    "test_label = df_test['class'].apply(lambda x: 1 if x == \"ce\" else 0).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=10,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  zoom_range=[0.95, 1.05],\n",
    "                                  fill_mode='constant', cval=0)\n",
    "valset_gen = ImageDataGenerator(rescale=1./255)\n",
    "testset_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T04:49:19.506140Z",
     "iopub.status.busy": "2021-04-29T04:49:19.505824Z",
     "iopub.status.idle": "2021-04-29T04:49:19.509719Z",
     "shell.execute_reply": "2021-04-29T04:49:19.508964Z",
     "shell.execute_reply.started": "2021-04-29T04:49:19.506107Z"
    }
   },
   "source": [
    "### Train: Augmentation CE x 6, Train Non-CE x 3 \n",
    "### Valid, Test: no augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ce_imgs = []\n",
    "for img_path in train_ce:\n",
    "    img = load_img(img_path)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    i = 0\n",
    "    for batch in data_aug_gen.flow(x, batch_size=1, seed=42):\n",
    "        train_ce_imgs.append(batch)\n",
    "        i += 1\n",
    "        if i == 6:\n",
    "            break\n",
    "train_ce_imgs = np.vstack(train_ce_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_non_ce_imgs = []\n",
    "for img_path in train_non_ce:\n",
    "    img = load_img(img_path)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    i = 0\n",
    "    for batch in data_aug_gen.flow(x, batch_size=1, seed=42):\n",
    "        train_non_ce_imgs.append(batch)\n",
    "        i += 1\n",
    "        if i == 3:\n",
    "            break\n",
    "train_non_ce_imgs = np.vstack(train_non_ce_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imgs = []\n",
    "for img_path in val_files:\n",
    "    img = load_img(img_path)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    for batch in valset_gen.flow(x, batch_size=1, shuffle = False, seed=42):\n",
    "        val_imgs.append(batch)\n",
    "        break\n",
    "val_imgs = np.vstack(val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = []\n",
    "for img_path in test_files:\n",
    "    img = load_img(img_path)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    for batch in testset_gen.flow(x, batch_size=1, shuffle = False, seed=42):\n",
    "        test_imgs.append(batch)\n",
    "        break\n",
    "test_imgs = np.vstack(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ce = [train_ce_imgs, np.repeat(1, train_ce_imgs.shape[0])]\n",
    "train_non_ce = [train_non_ce_imgs, np.repeat(0, train_non_ce_imgs.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = np.concatenate((train_ce[0], train_non_ce[0]), axis=0)\n",
    "train_label = np.concatenate((train_ce[1], train_non_ce[1]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "densenet = DenseNet121(\n",
    "    weights='./brucechou1983_CheXNet_Keras_0.3.0_weights.h5',\n",
    "    include_top=True,\n",
    "    input_shape=(224, 224, 3),\n",
    "    classes=14\n",
    ")\n",
    "out = layers.Dense(1, activation='sigmoid')(densenet.layers[-2].output)\n",
    "model = tf.keras.Model(inputs=densenet.input, outputs=out)\n",
    "\n",
    "\n",
    "trained_model_dir = './model_astrox/'\n",
    "model_name = 'model_ex-{epoch:03d}_acc-{val_loss:03f}.h5'\n",
    "model_path = os.path.join(trained_model_dir, model_name)\n",
    "\n",
    "\n",
    "# Callback\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=model_path,\n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=1,\n",
    "                                                save_weights_only=False,\n",
    "                                                save_best_only=True,\n",
    "                                                mode='auto',\n",
    "                                                save_freq='epoch')\n",
    "early_stopping = EarlyStopping(patience=50)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history_model = model.fit(train_img, train_label,\n",
    "                          validation_data=(val_imgs, val_label),\n",
    "                          epochs=epochs,\n",
    "                          shuffle=True,\n",
    "                          batch_size=batch_size,\n",
    "                          steps_per_epoch=len(train_img)//batch_size,\n",
    "                          callbacks=[checkpoint, early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "trained_model_dir = './model_astrox/'\n",
    "\n",
    "model = tf.keras.models.load_model(os.path.join(\n",
    "    trained_model_dir, os.listdir(trained_model_dir)[-1]))\n",
    "\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_label\n",
    "predictions = model.predict(test_imgs)\n",
    "y_pred = (predictions > 0.5).astype(np.int)\n",
    "y_proba = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
    "TP = conf_mat[0][0]\n",
    "TN = conf_mat[1][1]\n",
    "FN = conf_mat[0][1]\n",
    "FP = conf_mat[1][0]\n",
    "print(conf_mat)\n",
    "print(\"Acc\", (TP+TN)/(TP+TN+FP+FN))\n",
    "print(\"Sensitivity\", TP/(TP+FN))\n",
    "print(\"Specificity\", TN/(TN+FP))\n",
    "print(\"AUROC\", roc_auc_score(y_true, y_proba))\n",
    "print(\"Recall\", recall_score(y_true, y_pred))\n",
    "print(\"F1\",  f1_score(y_true, y_pred))\n",
    "print(\"Weighted accuracy\", balanced_accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
    "\n",
    "\n",
    "def plot_roc(fpr, tpr):\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label=\"random guess\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_roc(fpr, tpr)\n",
    "roc_auc_score(y_true, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_gradcam(model, IMAGE_PATH, LAYER_NAME):\n",
    "    image_array = IMAGE_PATH\n",
    "    img = image_array.astype(np.float32)\n",
    "\n",
    "    # Create a graph that outputs target convolution and output\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(LAYER_NAME).output, model.output])\n",
    "\n",
    "    # Get the score for target class\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.array([img]))\n",
    "        loss = predictions\n",
    "\n",
    "    # Extract filters and gradients\n",
    "    output = conv_outputs[0]\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "\n",
    "    # Average gradients spatially\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "\n",
    "    # Build a ponderated map of filters according to gradients importance\n",
    "    cam = np.ones(output.shape[0:2], dtype=np.float32)\n",
    "\n",
    "    for index, w in enumerate(weights):\n",
    "        cam += w * output[:, :, index]\n",
    "\n",
    "    # Heatmap visualization\n",
    "    cam = cv2.resize(cam.numpy(), (224, 224))\n",
    "    cam = np.maximum(cam, 0)\n",
    "\n",
    "    heatmap = ((cam - cam.min()) / (cam.max() - cam.min()))\n",
    "\n",
    "    cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "    alphanum = 0.6\n",
    "    output_image = cv2.addWeighted(cv2.cvtColor(\n",
    "        (image_array*255).astype('uint8'), cv2.COLOR_BGR2RGB), alphanum, cam, 1-alphanum, 0)\n",
    "    output_image = cv2.cvtColor(\n",
    "        output_image.astype('uint8'), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(model, IMAGE_PATH):\n",
    "    img = IMAGE_PATH\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    predictions = model.predict(img)\n",
    "    y_pred = (predictions > 0.5).astype(np.int)\n",
    "    return predictions, y_pred\n",
    "    print(predictions, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T06:34:42.671711Z",
     "iopub.status.busy": "2021-04-29T06:34:42.671406Z",
     "iopub.status.idle": "2021-04-29T06:34:42.674984Z",
     "shell.execute_reply": "2021-04-29T06:34:42.674325Z",
     "shell.execute_reply.started": "2021-04-29T06:34:42.671679Z"
    }
   },
   "source": [
    "### Save grad-cams for test dataset\n",
    "- file_name: id _ label _ sigmoid output _ predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_imgs)):\n",
    "    predictions = get_class(model, test_imgs[i])\n",
    "    output_image = get_gradcam(model, test_imgs[i], 'relu')\n",
    "    output_image = cv2.cvtColor(\n",
    "        output_image.astype('uint8'), cv2.COLOR_BGR2RGB)\n",
    "    file_name = './gradcam_astrox/' + str(i) + '_' + str(test_label[i]) + '_' + str(\n",
    "        predictions[0]) + '_' + str(predictions[1]) + '.jpg'\n",
    "    cv2.imwrite(file_name, output_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
